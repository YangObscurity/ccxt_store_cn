import sqlite3
import os
import time
import threading
import logging
from datetime import datetime, timedelta, timezone
from typing import Optional, List, Dict, Tuple
import pandas as pd
import numpy as np
from tqdm import tqdm
import queue
import ccxt
from cachetools import TTLCache
from tenacity import retry, stop_after_attempt, wait_exponential, wait_fixed,retry_if_exception_type
from config import ConfigManager
from logger import logger
class DataManager:
    def __init__(self, store=None):
        self.store = store
        self.config = ConfigManager().config
        self.cache = TTLCache(maxsize=200, ttl=600)
        self.db_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'data/tick.db'))
        self.symbol_metadata = {}
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å‚æ•°
        self.conn_params = {
            'database': self.db_path,
            'timeout': 30,
            'check_same_thread': False,
            'isolation_level': None
        }
        
        # åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
        self._create_tables()
        
        # ç»Ÿä¸€é”åç§°
        self.write_queue = queue.Queue(maxsize=10000)
        self.hist_lock = threading.Lock()
        self.gap_lock = threading.Lock()
        self.metadata_lock = threading.RLock()
        self._start_writer_thread()
        
        
        logger.debug(f"DataManageråˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½é…ç½®é¡¹: {list(self.config.keys())}")
        
    def _create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ï¼ˆä¿ç•™å®Œæ•´è¡¨ç»“æ„ï¼‰"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            
            # OHLCVè¡¨ï¼ˆä¿ç•™åˆ†é’Ÿå’Œå°æ—¶çº¿è¡¨ï¼‰
            for tf in ['1m', '1h']:
                conn.execute(f'''
                    CREATE TABLE IF NOT EXISTS ohlcv_{tf} (
                        symbol TEXT,
                        timestamp INTEGER,
                        open REAL CHECK(open > 0),
                        high REAL CHECK(high >= open AND high >= low),
                        low REAL CHECK(low <= open AND low <= high),
                        close REAL CHECK(close > 0),
                        volume REAL CHECK(volume >= 0),
                        PRIMARY KEY(symbol, timestamp)
                    ) WITHOUT ROWID
                ''')
            
            # ç¼ºå£è¡¨ï¼ˆä¿ç•™ç¼ºå£æ£€æµ‹åŠŸèƒ½ï¼‰
            conn.execute('''
                CREATE TABLE IF NOT EXISTS data_gaps (
                    symbol TEXT,
                    timeframe TEXT,
                    start_ts INTEGER CHECK(start_ts > 0),
                    end_ts INTEGER CHECK(end_ts > start_ts),
                    retries INTEGER DEFAULT 0 CHECK(retries >= 0),
                    next_retry_ts INTEGER CHECK(next_retry_ts > 0),
                    PRIMARY KEY(symbol, timeframe, start_ts)
                )
            ''')
            # åŒæ­¥è¿›åº¦è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS sync_progress (
                    symbol TEXT,
                    timeframe TEXT,
                    last_ts INTEGER,
                    PRIMARY KEY(symbol, timeframe)
                )
            ''')
            # å…ƒæ•°æ®è¡¨ï¼ˆæ–°å¢å¢å¼ºå‹å…ƒæ•°æ®ç®¡ç†ï¼‰
            conn.execute('''
                CREATE TABLE IF NOT EXISTS symbol_metadata (
                    symbol TEXT PRIMARY KEY,
                    first_ts INTEGER CHECK(first_ts > 0),
                    last_ts INTEGER CHECK(last_ts >= first_ts),
                    list_time INTEGER CHECK(list_time > 0)
                )
            ''')
            conn.commit()

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, max=60))
    def save_ohlcv_batch(self, symbol: str, timeframe: str, data: List[list]) -> int:
        valid = []
        min_ts = float('inf')
        max_ts = -float('inf')
        
        for row in data:
            if self._validate_ohlcv_row(row):
                ts = row[0]
                min_ts = min(min_ts, ts)
                max_ts = max(max_ts, ts)
                valid.append((symbol, ts, *map(float, row[1:])))
        
        if not valid:
            logger.warning(f"æ— æœ‰æ•ˆæ•°æ®å¯ä¿å­˜: {symbol} {timeframe}")
            return 0
        
        chunk_size = 500
        saved = 0
        table = f'ohlcv_{timeframe}'
        
        for i in range(0, len(valid), chunk_size):
            chunk = valid[i:i+chunk_size]
            try:
                with sqlite3.connect(**self.conn_params) as conn:
                    conn.executemany(
                        f'INSERT OR REPLACE INTO {table} VALUES (?,?,?,?,?,?,?)',
                        chunk
                    )
                    conn.execute('''
                        UPDATE symbol_metadata SET
                            first_ts = COALESCE(?, first_ts),
                            last_ts = COALESCE(?, last_ts)
                        WHERE symbol = ?
                    ''', (min_ts, max_ts, symbol))
                    conn.commit()
                    saved += conn.total_changes
            except sqlite3.IntegrityError as e:
                logger.error(f"æ•°æ®å†²çª: {str(e)}")
            except sqlite3.OperationalError as e:
                logger.error(f"æ•°æ®åº“é”å†²çª: {str(e)}, ç­‰å¾…åé‡è¯•...")
                time.sleep(0.5)
                raise
            except Exception as e:
                logger.error(f"æ•°æ®åº“å†™å…¥å¤±è´¥: {str(e)}")
                raise
        
        logger.debug(f"æˆåŠŸä¿å­˜{symbol} {timeframe}æ•°æ® {saved}æ¡")
        return saved

    def _validate_ohlcv_row(self, row: list) -> bool:
        if len(row) != 6:
            return False
        ts, o, h, l, c, v = row
        return (
            0 < o <= h and 
            l <= c <= h and 
            l > 0 and 
            v >= 0 and 
            1_614_393_600_000 <= ts <= 4_102_444_800_000
        )

    def _get_symbol_metadata(self, symbol: str) -> dict:
        if symbol in self.symbol_metadata:
            return self.symbol_metadata[symbol]
            
        with self.metadata_lock:
            with sqlite3.connect(**self.conn_params) as conn:
                row = conn.execute('''
                    SELECT first_ts, last_ts, list_time 
                    FROM symbol_metadata 
                    WHERE symbol = ?
                ''', (symbol,)).fetchone()
                
                if row:
                    meta = {'first_ts': row[0], 'last_ts': row[1], 'list_time': row[2]}
                else:
                    list_time = self._fetch_list_time(symbol)
                    meta = {'first_ts': None, 'last_ts': None, 'list_time': list_time}
                    conn.execute('''
                        INSERT INTO symbol_metadata (symbol, first_ts, last_ts, list_time)
                        VALUES (?, ?, ?, ?)
                    ''', (symbol, None, None, list_time))
                    conn.commit()
                self.symbol_metadata[symbol] = meta
                return meta
           
    def _fetch_list_time(self, symbol: str) -> int:
        """å¼ºåŒ–ä¸Šå¸‚æ—¶é—´è·å–é€»è¾‘"""
        try:
            exchange = self.store.exchange
            markets = exchange.load_markets(reload=True)
            
            if exchange.id == 'okx':
                inst_id = symbol.replace('/', '-')
                response = exchange.publicGetPublicInstruments({
                    'instType': 'SPOT', 
                    'instId': inst_id
                })
                list_time = int(response['data'][0]['listTime'])
            else:
                market = markets.get(symbol)
                list_time = market['info'].get('listing_date', market['timestamp'])
            
            # æ—¶é—´æˆ³æœ‰æ•ˆæ€§éªŒè¯
            current_ts = int(time.time() * 1000)
            if not (1000000000000 < list_time < current_ts):
                raise ValueError("Invalid listing time")
                
            return list_time
        except Exception as e:
            logger.error(f"è·å–ä¸Šå¸‚æ—¶é—´å¤±è´¥: {symbol} {str(e)}")
            # é»˜è®¤è¿”å›1å¹´å‰æ—¶é—´æˆ³
            return int((datetime.now(timezone.utc) - timedelta(days=365)).timestamp() * 1000)

    def fill_history(self, symbol: str, timeframe: str):
        """é‡æ„åçš„æ™ºèƒ½è¡¥å…¨æ–¹æ³•"""
        metadata = self._get_symbol_metadata(symbol)
        list_time = metadata['list_time']
        now_ts = int(time.time() * 1000)
        tf_ms = self._timeframe_to_ms(timeframe)
        
        # åŠ¨æ€è®¾ç½®æ—¶é—´èŒƒå›´
        if timeframe == '1h':
            max_days = 365
        elif timeframe == '1m':
            max_days = 30
        else:
            return

        end_ts = self._align_ts(now_ts, tf_ms)
        start_ts = end_ts - (max_days * 86400_000)
        actual_start_ts = max(list_time, start_ts)
        
        # è¯»å–åŒæ­¥è¿›åº¦
        saved_progress = self._get_sync_progress(symbol, timeframe)
        last_in_db = self.get_last_timestamp(symbol, timeframe)
        end_ts = min(last_in_db, end_ts) if last_in_db else end_ts
        current_ts = saved_progress if saved_progress else end_ts  # ä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„è¿›åº¦
        
        logger.info(f"æ™ºèƒ½è¡¥å…¨èŒƒå›´: {self._ts_to_str(actual_start_ts)} -> {self._ts_to_str(end_ts)}")
        
        success = False
        with self.hist_lock, tqdm(desc=f"ğŸ“š {symbol} {timeframe}", unit="é¡µ") as pbar:
            try:
                while current_ts > actual_start_ts:
                    batch_start = max(current_ts - 1000 * tf_ms, actual_start_ts)
                    
                    data = self._safe_fetch_ohlcv(
                        symbol, timeframe, 
                        since=batch_start,
                        limit=1000
                    )
                    
                    if not data:
                        break
                    
                    valid_data = [row for row in data if actual_start_ts <= row[0] <= end_ts]
                    if not valid_data or valid_data[0][0] >= current_ts:
                        break
                    
                    self.save_ohlcv_batch(symbol, timeframe, valid_data)
                    pbar.update(len(valid_data))
                    current_ts = self._align_ts(valid_data[0][0] - tf_ms, tf_ms)
                    self._save_progress(symbol, timeframe, current_ts)  # å®æ—¶ä¿å­˜è¿›åº¦
                    
                    time.sleep(max(0.3, self.store.exchange.rateLimit / 3000))
                
                oldest = self.get_oldest_timestamp(symbol, timeframe) or 0
                latest = self.get_last_timestamp(symbol, timeframe) or 0
                success = (oldest <= actual_start_ts) and (latest >= end_ts)
            except Exception as e:
                logger.error(f"è¡¥å…¨ä¸­æ–­: {symbol} {timeframe} {str(e)}")
                self._save_progress(symbol, timeframe, current_ts)
                success = False
        
        if success:
            logger.info(f"è¡¥å…¨å®Œæˆ: {symbol} {timeframe}")
            self._mark_as_repaired(symbol, timeframe)
        else:
            logger.warning(f"æ•°æ®ä¸å®Œæ•´: {symbol} {timeframe}")
    
    def _mark_as_repaired(self, symbol: str, timeframe: str):
        """æ ‡è®°æ•°æ®å·²ä¿®å¤"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO sync_progress 
                (symbol, timeframe, last_ts) 
                VALUES (?, ?, ?)
            ''', (symbol, timeframe, int(time.time()*1000)))
            conn.commit()

    def _save_progress(self, symbol, tf, current_ts):
        """ä¿å­˜è¡¥å…¨è¿›åº¦"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO sync_progress 
                (symbol, timeframe, last_ts) 
                VALUES (?, ?, ?)
            ''', (symbol, tf, current_ts))
            conn.commit()

    def _get_sync_progress(self, symbol, tf):
        """è·å–è¡¥å…¨è¿›åº¦"""
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute('''
                SELECT last_ts FROM sync_progress
                WHERE symbol=? AND timeframe=?
            ''', (symbol, tf)).fetchone()
            return row[0] if row else None

    @retry(stop=stop_after_attempt(3),
       wait=wait_fixed(2),
       retry=retry_if_exception_type((ccxt.NetworkError, ccxt.ExchangeError, KeyError)))
    def _safe_fetch_ohlcv(self, symbol: str, timeframe: str, since: int, limit: int):
        """ç»Ÿä¸€ç‰ˆæ•°æ®è·å–æ–¹æ³•ï¼ˆåˆå¹¶ä¸¤ä¸ªé‡å¤å®ç°ï¼‰"""
        retries = 0
        max_retries = 3
        tf_ms = self._timeframe_to_ms(timeframe)
        
        while retries < max_retries:
            try:
                # å¯¹é½æ—¶é—´æˆ³é¿å…åˆ†é¡µé”™ä½
                aligned_since = self._align_ts(since, tf_ms)
                
                data = self.store.exchange.fetch_ohlcv(
                    symbol,
                    timeframe=timeframe,
                    since=aligned_since,
                    limit=limit,
                    params={'instType': 'SPOT'}
                )
                
                if not data:
                    return []

                # ä¸¥æ ¼éªŒè¯æ—¶é—´åºåˆ—å’ŒèŒƒå›´ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
                expected_max_ts = aligned_since + (limit * tf_ms)
                prev_ts = None
                for idx, row in enumerate(data):
                    current_ts = row[0]
                    if current_ts > expected_max_ts:
                        raise ValueError(f"æ•°æ®è¶…å‡ºè¯·æ±‚èŒƒå›´ {current_ts} > {expected_max_ts}")
                    if prev_ts and current_ts <= prev_ts:
                        raise ValueError(f"æ—¶é—´æˆ³éé€’å¢ {prev_ts} -> {current_ts}")
                    prev_ts = current_ts

                return data
            except ccxt.NetworkError as e:
                logger.warning(f"ç½‘ç»œé”™è¯¯({retries+1}/{max_retries}): {str(e)}")
                time.sleep(2 ** retries)
                retries += 1
            except ccxt.ExchangeError as e:
                logger.warning(f"äº¤æ˜“æ‰€é”™è¯¯({retries+1}/{max_retries}): {str(e)}")
                time.sleep(2 ** retries)
                retries += 1
            except Exception as e:
                logger.error(f"æ•°æ®è·å–å¤±è´¥: {str(e)}")
                raise
        return []        
    
    def _start_writer_thread(self):
        """å¯åŠ¨å¼‚æ­¥å†™å…¥çº¿ç¨‹"""
        def writer():
            while True:
                try:
                    task = self.write_queue.get(timeout=5)
                    if task is None:
                        break
                    self.save_ohlcv_batch(**task)
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                    
        threading.Thread(target=writer, daemon=True, name="DBWriter").start()

    @staticmethod
    def _align_ts(ts: int, timeframe_ms: int) -> int:
        """æ—¶é—´æˆ³å¯¹é½"""
        return (ts // timeframe_ms) * timeframe_ms

    @staticmethod
    def _timeframe_to_ms(timeframe: str) -> int:
        return {
            '1m': 60_000,
            '1h': 3_600_000,
            '1d': 86_400_000
        }[timeframe]

    def get_ohlcv_count(self, symbol: str, timeframe: str) -> int:
        """è·å–æ•°æ®é‡"""
        table = f'ohlcv_{timeframe}'
        with sqlite3.connect(**self.conn_params) as conn:
            return conn.execute(f'SELECT COUNT(*) FROM {table} WHERE symbol = ?', (symbol,)).fetchone()[0]

    def get_last_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        """è·å–æœ€æ–°æ—¶é—´æˆ³"""
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute(
                f'SELECT MAX(timestamp) FROM ohlcv_{timeframe} WHERE symbol = ?',
                (symbol,)
            ).fetchone()
            return row[0] if row else None

    def check_and_fill_gaps(self, symbol: str, timeframe: str):
        """æœ€ç»ˆç‰ˆç¼ºå£å¤„ç†"""
        if not self._should_process(symbol, timeframe, 'gap'):
            return

        try:
            with self.gap_lock:
                logger.info(f"ğŸ—ï¸ å¯åŠ¨ç¼ºå£æ‰«æ: {symbol} {timeframe}")
                gaps = self._precision_detect_gaps(symbol, timeframe)
                
                # æœ‰æ•ˆæ€§éªŒè¯
                valid_gaps = []
                for start, end in gaps:
                    if start >= end:
                        continue
                    if end > int(time.time()*1000):
                        end = int(time.time()*1000)
                    valid_gaps.append((start, end))
                
                if not valid_gaps:  # æ–°å¢åˆ¤æ–­
                    logger.info("æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ•°æ®ç¼ºå£")
                    return
                
                with tqdm(
                    total=len(valid_gaps),
                    desc=f"ğŸ”§ {symbol} {timeframe} ç¼ºå£ä¿®å¤",
                    bar_format="{desc}: {percentage:.0f}%|{bar}| {n_fmt}/{total_fmt}"
                ) as pbar:
                    success_count = 0
                    for start, end in valid_gaps:
                        if self._fill_single_gap(symbol, timeframe, start, end, pbar):
                            success_count += 1
                        pbar.update(1)
                    
                    status_msg = (
                        f"ç¼ºå£å¤„ç†å®Œæˆ | æœ‰æ•ˆç¼ºå£: {len(valid_gaps)}ä¸ª | "
                        f"æˆåŠŸ: {success_count}ä¸ª | å¤±è´¥: {len(valid_gaps)-success_count}ä¸ª"
                    )
                    logger.info(status_msg)
        except Exception as e:
            logger.error(f"ç¼ºå£å¤„ç†å¼‚å¸¸: {str(e)}", exc_info=True)
        finally:
            self._clean_processed_gaps(symbol, timeframe)

    def _record_failed_gaps(self, symbol: str, timeframe: str, start: int, end: int):
        """è®°å½•å¤±è´¥ç¼ºå£"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                UPDATE data_gaps SET 
                    retries = retries + 1,
                    next_retry_ts = ?
                WHERE symbol=? AND timeframe=? AND start_ts=?
            ''', (int(time.time()*1000) + 3600000, symbol, timeframe, start))
            conn.commit()

    def _fill_single_gap(self, symbol, tf, start, end, pbar):
        """ä¼˜åŒ–ç‰ˆå•ç¼ºå£è¡¥å…¨"""
        tf_ms = self._timeframe_to_ms(tf)
        current = start
        success = False
        
        try:
            while current <= end:
                data = self._safe_fetch_ohlcv(symbol, tf, current, 1000)
                if not data:
                    break
                
                # ä½¿ç”¨æ–°çš„èŒƒå›´è¿‡æ»¤æ–¹æ³•
                valid = self._filter_data_by_range(data, start, end)
                if not valid:
                    break
                
                self.save_ohlcv_batch(symbol, tf, valid)
                pbar.update(len(valid))
                current = valid[-1][0] + tf_ms
                success = True
            
            return success
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {start}-{end}: {str(e)}")
            return False

    def _filter_data_by_range(self, data, start, end):
        """ç»Ÿä¸€æ•°æ®è¿‡æ»¤æ–¹æ³•"""
        return [d for d in data if start <= d[0] <= end]

    def _precision_detect_gaps(self, symbol, tf):
        """ç²¾ç¡®ç¼ºå£æ£€æµ‹"""
        table = f'ohlcv_{tf}'
        step = self._timeframe_to_ms(tf)
        gaps = []
        current_ts = int(time.time() * 1000)
        
        with sqlite3.connect(**self.conn_params) as conn:
            df = pd.read_sql(f'''
                SELECT timestamp FROM {table}
                WHERE symbol = '{symbol}'
                AND timestamp <= {current_ts}
                ORDER BY timestamp
            ''', conn)
            
            if len(df) < 2:
                return []
            
            df['prev'] = df['timestamp'].shift(1)
            df['gap'] = df['timestamp'] - df['prev'] - step
            anomalies = df[(df['gap'] > step * 1.1) & (df['gap'] < step * 1000)]
            
            for _, row in anomalies.iterrows():
                gap_start = int(row['prev'] + step)
                gap_end = int(row['timestamp'] - step)
                # ä¸å½“å‰æ—¶é—´å¯¹é½
                gaps.append((
                    gap_start,
                    min(gap_end, current_ts)
                ))
        
        return gaps

    def _should_process(self, symbol: str, tf: str, process_type: str) -> bool:
        """æ‰§è¡Œæ¡ä»¶æ£€æŸ¥"""
        config = ConfigManager().config
        if symbol not in config['spot_symbols']:
            return False
        if process_type == 'gap' and not config.get('enable_gap_filling', False):
            return False
        if process_type == 'historical' and not config.get('enable_historical_fill', False):
            return False
        if not self.store.exchange.has['fetchOHLCV']:
            return False
        return True
       
    def save_plot_data(self, symbol: str, timeframe: str, data: dict):
        """ä¿å­˜ç­–ç•¥ç”Ÿæˆçš„ç»˜å›¾æ•°æ®ï¼ˆåŸæ–¹æ³•ä¼˜åŒ–ç‰ˆï¼‰"""
        try:
            if not data or len(data['time']) == 0:
                logger.warning(f"ç©ºç»˜å›¾æ•°æ®: {symbol} {timeframe}")
                return

            # å¢å¼ºæ•°æ®éªŒè¯
            required_fields = ['time', 'price', 'ma', 'rsi', 'atr']
            for field in required_fields:
                if field not in data or len(data[field]) == 0:
                    raise ValueError(f"ç¼ºå¤±å¿…è¦å­—æ®µ: {field}")

            df = pd.DataFrame({
                'time': pd.to_datetime(data['time'], unit='ms', utc=True),
                'price': data['price'],
                'ma': data['ma'],
                'rsi': data['rsi'],
                'atr': data['atr'],
                'signals': [str(s) if s else None for s in data.get('signals', [None]*len(data['time']))]
            })
            df['symbol'] = symbol
            df['timeframe'] = timeframe
            
            # ä½¿ç”¨æ‰¹é‡å†™å…¥é˜Ÿåˆ—
            self.write_queue.put({
                'type': 'plot',
                'symbol': symbol,
                'timeframe': timeframe,
                'data': df
            })
            logger.debug(f"ç»˜å›¾æ•°æ®è¿›å…¥é˜Ÿåˆ—: {symbol} {timeframe} {len(df)}æ¡")
            
        except Exception as e:
            logger.error(f"å‡†å¤‡ç»˜å›¾æ•°æ®å¤±è´¥: {str(e)}")

    def get_oldest_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        """è·å–æœ€æ—©æ—¶é—´æˆ³"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            row = conn.execute(f'''
                SELECT MIN(timestamp) FROM {table}
                WHERE symbol = ?
            ''', (symbol,)).fetchone()
            return row[0] if row[0] else None
    @retry(stop=stop_after_attempt(3), wait=wait_fixed(60))
    def sync_symbol(self, symbol: str):
        try:
            # å…ˆæ‰§è¡Œå†å²æ•°æ®è¡¥å…¨
            if self.config.get('fill_history', False):
                logger.info(f"å¼ºåˆ¶å†å²æ•°æ®è¡¥å…¨: {symbol}")
                for tf in ['1h', '1m']:  # å…ˆå°æ—¶çº¿ååˆ†é’Ÿçº¿
                    self.fill_history(symbol, tf)
                return True
            # åŸæœ‰å®æ—¶åŒæ­¥
            if not self.fetch_ohlcv(symbol):
                return False
            return True
        except Exception as e:
            logger.error(f"åŒæ­¥å¤±è´¥: {symbol} - {str(e)}")
            return False
    
    def _clear_existing_data(self, symbol: str, timeframe: str):
        """æ¸…é™¤ç°æœ‰æ•°æ®ä»¥å¼ºåˆ¶é‡æ–°åŒæ­¥"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            conn.execute(f'DELETE FROM {table} WHERE symbol = ?', (symbol,))
            logger.warning(f"å·²æ¸…é™¤{symbol} {timeframe}çš„ç°æœ‰æ•°æ®")

    def set_progress_queue(self, queue):
        self.progress_queue = queue

    def _update_progress(self, n: int = 1):
        if self.progress:
            self.progress.update(n)
            if self.progress_queue:
                try:
                    self.progress_queue.put_nowait((
                        self.current_symbol,
                        self.current_tf,
                        self.progress.n,
                        self.progress.total
                    ))
                except queue.Full:
                    pass
    
    def ensure_data_range(self, symbol: str, timeframe: str) -> bool:
        """ç¡®ä¿æ•°æ®æ»¡è¶³ç­–ç•¥éœ€æ±‚"""
        # è‡ªåŠ¨è®¡ç®—æ—¶é—´èŒƒå›´
        now = int(time.time() * 1000)
        if timeframe == '1h':
            required_start = now - 365 * 86400_000
        elif timeframe == '1m':
            required_start = now - 30 * 86400_000
        else:
            return True
        
        # è·å–å®é™…æ•°æ®è¾¹ç•Œ
        oldest = self.get_oldest_timestamp(symbol, timeframe) or required_start
        latest = self.get_last_timestamp(symbol, timeframe) or now
        
        # æ‰§è¡ŒåŒå‘è¡¥å…¨
        success = True
        if oldest > required_start:
            success &= self._fill_range(symbol, timeframe, required_start, oldest)
        if latest < now:
            success &= self._fill_range(symbol, timeframe, latest, now)
        
        return success
    
    @staticmethod
    def _ts_to_str(ts: int) -> str:
        return datetime.fromtimestamp(ts/1000).strftime('%Y-%m-%d %H:%M')

    def _fill_range(self, symbol: str, timeframe: str, start: int, end: int) -> bool:
        """ç²¾ç¡®å¡«å……æ—¶é—´èŒƒå›´"""
        tf_ms = self._timeframe_to_ms(timeframe)
        current = end
        total = 0
        max_attempts = 1000
        
        with tqdm(total=(end - start) // tf_ms, desc=f"å¡«å……{symbol} {timeframe}") as pbar:
            for _ in range(max_attempts):
                if current <= start:
                    break
                    
                data = self._safe_fetch_ohlcv(symbol, timeframe, current - 1000*tf_ms, 1000)
                if not data:
                    break
                    
                valid = [d for d in data if start <= d[0] <= end]
                if not valid:
                    break
                    
                self.save_ohlcv_batch(symbol, timeframe, valid)
                saved = len(valid)
                total += saved
                pbar.update(saved)
                current = valid[0][0] - tf_ms
                
                time.sleep(max(0.5, self.store.exchange.rateLimit / 1000))
                
        return total > 0

    def _validate_timestamp_continuity(self, symbol: str, timeframe: str):
        """æ—¶é—´è¿ç»­æ€§æ ¡éªŒ"""
        table = f'ohlcv_{"1m" if timeframe == "1m" else "1h"}'
        expected_step = self._timeframe_to_ms(timeframe)
        
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            df = pd.read_sql(f'''
                SELECT timestamp,
                       (timestamp - LAG(timestamp) OVER (ORDER BY timestamp)) AS diff
                FROM {table}
                WHERE symbol = '{symbol}'
                ORDER BY timestamp
            ''', conn)
            
            anomalies = df[df['diff'] > (expected_step + 1000)]
            if not anomalies.empty:
                logger.warning(f"å‘ç°{len(anomalies)}å¤„æ—¶é—´å¼‚å¸¸ {symbol} {timeframe}")

    def set_progress_queue(self, queue):
        """è®¾ç½®å¯è§†åŒ–è¿›åº¦é˜Ÿåˆ—"""
        self.progress_queue = queue

    def auto_repair_gaps(self):
        """åå°è‡ªåŠ¨ä¿®å¤ç¼ºå£"""
        while True:
            try:
                for symbol in self.config['spot_symbols']:
                    for tf in ['1m', '1h']:
                        if self._precision_detect_gaps(symbol, tf) > 0:
                            self._fill_gaps(symbol, tf)
                time.sleep(3600)  # æ¯å°æ—¶è¿è¡Œä¸€æ¬¡
            except Exception as e:
                logger.error(f"è‡ªåŠ¨ä¿®å¤å¼‚å¸¸: {str(e)}")

    def _get_symbol_list_time(self, symbol: str) -> int:
        """å¼ºåŒ–ä¸Šå¸‚æ—¶é—´è·å–é€»è¾‘"""
        if symbol in self.symbol_metadata:
            return self.symbol_metadata[symbol]['list_time']

        try:
            markets = self.store.exchange.load_markets(reload=True)
            market = markets.get(symbol)
            if not market:
                logger.error(f"æ‰¾ä¸åˆ°äº¤æ˜“å¯¹: {symbol}")
                return self._default_list_time()

            # å¤šäº¤æ˜“æ‰€å…¼å®¹é€»è¾‘
            exchange_name = self.config['exchange']['name'].lower()
            info = market.get('info', {})
            
            # OKXç‰¹æ®Šå¤„ç†
            if exchange_name == 'okx':
                list_time = int(info.get('listTime', 0))
                if list_time == 0:
                    # ä»å¸ç§ä¿¡æ¯ä¸­æå–
                    inst_id = market['id']
                    response = self.store.exchange.publicGetPublicInstruments(params={
                        'instType': 'SPOT',
                        'instId': inst_id
                    })
                    list_time = int(response['data'][0]['listTime'])
            else:
                # å…¶ä»–äº¤æ˜“æ‰€å¤„ç†
                list_time = market.get('timestamp', None) or info.get('listing_date', 0)
            
            # æœ€ç»ˆæ ¡éªŒ
            current_ts = int(time.time() * 1000)
            if not (1000000000000 < list_time < current_ts):
                logger.warning(f"å¼‚å¸¸ä¸Šå¸‚æ—¶é—´ {symbol}: {list_time}, ä½¿ç”¨é»˜è®¤å€¼")
                list_time = self._default_list_time()
            
            self.symbol_metadata[symbol] = {
                'list_time': list_time,
                'first_ts': None,
                'last_ts': None
            }
            logger.info(f"ç¡®å®šä¸Šå¸‚æ—¶é—´ {symbol}: {datetime.fromtimestamp(list_time/1000)}")
            return list_time
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šå¸‚æ—¶é—´å¤±è´¥ {symbol}: {str(e)}")
            return self._default_list_time()
        
    def _align_timestamp(self, ts: int, timeframe: str) -> int:
        """ç­–ç•¥çº§æ—¶é—´å¯¹é½ï¼ˆæ”¯æŒå¤šæ—¶é—´å¸§ï¼‰"""
        if timeframe == '1h':
            return ts - (ts % 3_600_000)  # æ•´å°æ—¶å¯¹é½
        elif timeframe == '1m':
            return ts - (ts % 60_000)     # æ•´åˆ†é’Ÿå¯¹é½
        else:
            return ts
    
    def _db_writer_loop(self):
        """ä¸“ç”¨å†™çº¿ç¨‹å¾ªç¯"""
        while True:
            task = None
            try:
                task = self.write_queue.get(timeout=5)
                with self.db_lock:
                    conn = sqlite3.connect(self.db_path, timeout=30)
                    try:
                        conn.executemany(task['query'], task['data'])
                        conn.commit()
                        logger.debug(f"æ‰¹é‡å†™å…¥å®Œæˆ {len(task['data'])}æ¡")
                    finally:
                        conn.close()
            except queue.Empty:
                continue
            except sqlite3.OperationalError as e:
                logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œç­‰å¾…åé‡è¯•: {str(e)}")
                time.sleep(5)
            except Exception as e:
                logger.error(f"æ•°æ®åº“å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
                time.sleep(5)

            finally:
                if task is not None:
                    self.write_queue.task_done()
    
    def _safe_release_lock(self, lock: threading.Lock):
        """å®‰å…¨é‡Šæ”¾é”"""
        try:
            if lock.locked():
                lock.release()
        except RuntimeError as e:
            logger.warning(f"é”é‡Šæ”¾å¼‚å¸¸: {str(e)}")

    def _start_writer_thread(self):
        """ç»Ÿä¸€ç‰ˆå†™å…¥çº¿ç¨‹"""
        def writer():
            while True:
                try:
                    task = self.write_queue.get(timeout=5)
                    if task is None:  # æ¥æ”¶åˆ°ç»ˆæ­¢ä¿¡å·
                        break
                        
                    # åŠ¨æ€å¤„ç†ä»»åŠ¡ç±»å‹
                    if task['type'] == 'ohlcv':
                        self._save_ohlcv_task(task)
                    elif task['type'] == 'plot':
                        self._save_plot_task(task)
                    elif task['type'] == 'sync':
                        self._handle_sync_task(task)
                        
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)

        threading.Thread(target=writer, daemon=True, name="DBWriter").start()

    def _save_ohlcv_task(self, task):
        """å¤„ç†OHLCVæ•°æ®å†™å…¥"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.executemany(
                task['query'],
                task['data']
            )
            conn.commit()

    def _save_plot_task(self, task):
        """ä¿å­˜ç»˜å›¾æ•°æ®"""
        df = task['data']
        try:
            with sqlite3.connect(**self.conn_params) as conn:
                df.to_sql('plot_data', conn, if_exists='append', index=False)
            logger.debug(f"ä¿å­˜ç»˜å›¾æ•°æ®æˆåŠŸ: {task['symbol']} {task['timeframe']} {len(df)}æ¡")
        except sqlite3.IntegrityError:
            logger.warning(f"å¿½ç•¥é‡å¤ç»˜å›¾æ•°æ®: {task['symbol']} {task['timeframe']}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç»˜å›¾æ•°æ®å¤±è´¥: {str(e)}")

    def get_ohlcv_count(self, symbol: str, timeframe: str) -> int:
        """è·å–æŒ‡å®šå“ç§çš„æ•°æ®é‡"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            return conn.execute(f'''
                SELECT COUNT(*) FROM {table}
                WHERE symbol = ?
            ''', (symbol,)).fetchone()[0]
 
    def _should_process(self, symbol: str, tf: str, process_type: str) -> bool:
        config = ConfigManager().config
        if symbol not in config['spot_symbols']:
            return False
            
        # ä½¿ç”¨æ–°çš„é…ç½®ç»“æ„
        if process_type == 'gap':
            return config['gap_fill'].get('enabled', False)
            
        if process_type == 'historical':
            return config['historical_fill'].get('enabled', False)
            
        if not self.store.exchange.has['fetchOHLCV']:
            return False
            
        return True

    def print_lock_status(self):
        """è°ƒè¯•ç”¨é”çŠ¶æ€æ‰“å°"""
        status = {
            'hist_lock': self.hist_lock.locked(),
            'gap_lock': self.gap_lock.locked(),
            'write_queue_size': self.write_queue.qsize()
        }
        logger.debug(f"é”çŠ¶æ€: {status}")
    
    def _fill_gaps(self, symbol: str, timeframe: str, pbar: tqdm) -> int:
        filled = 0
        try:
            table = f'ohlcv_{timeframe}'
            expected_step = self._timeframe_to_ms(timeframe)
            
            with sqlite3.connect(**self.conn_params) as conn:
                # è·å–å¾…å¤„ç†ç¼ºå£
                gaps = conn.execute('''
                    SELECT start_ts, end_ts FROM data_gaps
                    WHERE symbol = ? AND timeframe = ?
                    ORDER BY start_ts
                ''', (symbol, timeframe)).fetchall()
                
                for start_ts, end_ts in gaps:
                    current = start_ts
                    while current < end_ts:
                        data = self._safe_fetch_ohlcv(
                            symbol, 
                            timeframe, 
                            current, 
                            1000
                        )
                        
                        if not data:
                            break
                            
                        # ä¸¥æ ¼è¿‡æ»¤æœ‰æ•ˆæ•°æ®èŒƒå›´
                        valid_data = [
                            row for row in data 
                            if start_ts <= row[0] <= end_ts
                        ]
                        
                        if not valid_data:
                            break
                        
                        # æ‰¹é‡ä¿å­˜æ•°æ®
                        self.save_ohlcv_batch(symbol, timeframe, valid_data)
                        filled += len(valid_data)
                        pbar.update(len(valid_data))
                        
                        # æ›´æ–°è¿›åº¦æŒ‡é’ˆ
                        current = valid_data[-1][0] + expected_step
                    
                    # åˆ é™¤å·²å¤„ç†ç¼ºå£
                    conn.execute('''
                        DELETE FROM data_gaps 
                        WHERE symbol=? AND timeframe=? AND start_ts=?
                    ''', (symbol, timeframe, start_ts))
                    conn.commit()
                    
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {symbol} {timeframe}: {str(e)}")
            return filled
        return filled
    
    def _default_list_time(self) -> int:
        return int((datetime.now(timezone.utc) - timedelta(days=365)).timestamp() * 1000)

    def _close_db_connections(self):
        if hasattr(self, 'conn') and self.conn:
            try:
                if self.conn.in_transaction:
                    self.conn.commit()  # æˆ–rollbackæ ¹æ®éœ€æ±‚
                self.conn.close()
                logger.debug("æ•°æ®åº“è¿æ¥å·²å®‰å…¨å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {str(e)}")
            finally:
                self.conn = None

    def get_last_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        table = f'ohlcv_{timeframe}'
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute(
                f'SELECT MAX(timestamp) FROM {table} WHERE symbol = ?',
                (symbol,)
            ).fetchone()
            return row[0] if row else None

    def _get_last_timestamp(self, symbol: str) -> int:
        with sqlite3.connect(**self.conn_params) as conn:
            cur = conn.execute('''
                SELECT MAX(timestamp) FROM ohlcv_1m WHERE symbol = ?
            ''', (symbol,))
            result = cur.fetchone()[0]
            return result or int((datetime.now() - timedelta(days=30)).timestamp() * 1000)

    def _safe_fetch_with_progress(self, symbol, tf, since, limit, pbar):
        """å¸¦è¿›åº¦è·Ÿè¸ªçš„æ•°æ®è·å–"""
        try:
            data = self._safe_fetch_ohlcv(symbol, tf, since, limit)
            if not data:
                return None
                
            valid = [row for row in data if row[0] > since]
            if valid:
                self.save_ohlcv_batch(symbol, tf, valid)
                pbar.update(len(valid))
            return valid
        except Exception as e:
            logger.error(f"è·å–å¤±è´¥: {symbol} {tf} {str(e)}")
            return None

    def _fill_single_gap(self, symbol, tf, start, end, pbar):
        """å•ç¼ºå£è¡¥å…¨"""
        tf_ms = self._timeframe_to_ms(tf)
        current = start
        success = False
        
        try:
            while current <= end:
                data = self._safe_fetch_ohlcv(symbol, tf, current, 1000)
                if not data:
                    break
                
                valid = [d for d in data if start <= d[0] <= end]
                if not valid:
                    break
                
                self.save_ohlcv_batch(symbol, tf, valid)
                pbar.update(len(valid))
                current = valid[-1][0] + tf_ms
                success = True
            
            return success
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {start}-{end}: {str(e)}")
            return False
        
    def _clean_processed_gaps(self, symbol: str, timeframe: str):
        """æ¸…ç†å·²å¤„ç†æˆ–è¿‡æœŸçš„ç¼ºå£è®°å½•"""
        try:
            with sqlite3.connect(**self.conn_params) as conn:
                # åˆ é™¤è¶…è¿‡3æ¬¡é‡è¯•çš„ç¼ºå£è®°å½•
                conn.execute('''
                    DELETE FROM data_gaps 
                    WHERE symbol = ? 
                    AND timeframe = ?
                    AND retries >= 3
                ''', (symbol, timeframe))
                
                # åˆ é™¤å·²ç»ä¸å­˜åœ¨æ—¶é—´èŒƒå›´å†…çš„ç¼ºå£ï¼ˆé˜²æ­¢æ®‹ç•™ï¼‰
                conn.execute('''
                    DELETE FROM data_gaps 
                    WHERE symbol = ? 
                    AND timeframe = ?
                    AND end_ts < (
                        SELECT MIN(timestamp) 
                        FROM ohlcv_''' + timeframe + '''
                        WHERE symbol = ?
                    )
                ''', (symbol, timeframe, symbol))
                
                conn.commit()
                logger.debug(f"æ¸…ç†å®Œæˆ {symbol} {timeframe} çš„è¿‡æœŸç¼ºå£è®°å½•")
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼ºå£è®°å½•å¤±è´¥: {str(e)}")

