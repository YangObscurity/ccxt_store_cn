import sqlite3
import os
import time
import threading
import logging
from datetime import datetime, timedelta, timezone
from typing import Optional, List, Dict, Tuple
import pandas as pd
import numpy as np
from tqdm import tqdm
import queue
import ccxt
from cachetools import TTLCache
from tenacity import retry, stop_after_attempt, wait_exponential, wait_fixed,retry_if_exception_type
from config import ConfigManager
from logger import logger
class DataManager:
    def __init__(self, store=None):
        self.store = store
        self.config = ConfigManager().config
        self.cache = TTLCache(maxsize=200, ttl=600)
        self.db_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'data/tick.db'))
        self.symbol_metadata = {}
        self.progress_queue = None
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å‚æ•°
        self.conn_params = {
            'database': self.db_path,
            'timeout': 30,
            'check_same_thread': False,
            'isolation_level': None
        }
        
        # åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
        self._create_tables()
        
        # ç»Ÿä¸€é”åç§°
        self.write_queue = queue.Queue(maxsize=10000)
        self.hist_lock = threading.Lock()
        self.gap_lock = threading.Lock()
        self.metadata_lock = threading.RLock()
        self._start_writer_thread()
        
        
        logger.debug(f"DataManageråˆå§‹åŒ–å®Œæˆï¼ŒåŠ è½½é…ç½®é¡¹: {list(self.config.keys())}")
        
    def _create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ï¼ˆä¿ç•™å®Œæ•´è¡¨ç»“æ„ï¼‰"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            
            # OHLCVè¡¨ï¼ˆä¿ç•™åˆ†é’Ÿå’Œå°æ—¶çº¿è¡¨ï¼‰
            for tf in ['1m', '1h']:
                conn.execute(f'''
                    CREATE TABLE IF NOT EXISTS ohlcv_{tf} (
                        symbol TEXT,
                        timestamp INTEGER,
                        open REAL CHECK(open > 0),
                        high REAL CHECK(high >= open AND high >= low),
                        low REAL CHECK(low <= open AND low <= high),
                        close REAL CHECK(close > 0),
                        volume REAL CHECK(volume >= 0),
                        PRIMARY KEY(symbol, timestamp)
                    ) WITHOUT ROWID
                ''')
            # ç»˜å›¾æ•°æ®è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS plot_data (
                    time INTEGER,
                    symbol TEXT,
                    timeframe TEXT,
                    price REAL,
                    ma REAL,
                    rsi REAL,
                    atr REAL,
                    signals TEXT,
                    PRIMARY KEY(symbol, timeframe, time)
                )
            ''')
            # ç¼ºå£è¡¨ï¼ˆä¿ç•™ç¼ºå£æ£€æµ‹åŠŸèƒ½ï¼‰
            conn.execute('''
                CREATE TABLE IF NOT EXISTS data_gaps (
                    symbol TEXT,
                    timeframe TEXT,
                    start_ts INTEGER CHECK(start_ts > 0),
                    end_ts INTEGER CHECK(end_ts > start_ts),
                    retries INTEGER DEFAULT 0 CHECK(retries >= 0),
                    next_retry_ts INTEGER CHECK(next_retry_ts > 0),
                    PRIMARY KEY(symbol, timeframe, start_ts)
                )
            ''')
            # åŒæ­¥è¿›åº¦è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS sync_progress (
                    symbol TEXT,
                    timeframe TEXT,
                    last_ts INTEGER,
                    PRIMARY KEY(symbol, timeframe)
                )
            ''')
            # å…ƒæ•°æ®è¡¨ï¼ˆæ–°å¢å¢å¼ºå‹å…ƒæ•°æ®ç®¡ç†ï¼‰
            conn.execute('''
                CREATE TABLE IF NOT EXISTS symbol_metadata (
                    symbol TEXT PRIMARY KEY,
                    first_ts INTEGER CHECK(first_ts > 0),
                    last_ts INTEGER CHECK(last_ts >= first_ts),
                    list_time INTEGER CHECK(list_time > 0)
                )
            ''')
            conn.commit()

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, max=60))
    def save_ohlcv_batch(self, symbol: str, timeframe: str, data: List[list]) -> int:
        valid = []
        min_ts = float('inf')
        max_ts = -float('inf')
        table = f'ohlcv_{timeframe}'
        chunk_size = 500
        saved = 0

        # æ—¶é—´æˆ³æ ‡å‡†åŒ–å¤„ç†
        for row in data:
            if len(row) != 6:
                continue
                
            raw_ts = row[0]
            # è‡ªåŠ¨è¯†åˆ«æ—¶é—´æˆ³æ ¼å¼
            if 1e9 <= raw_ts < 1e10:    # ç§’çº§æ—¶é—´æˆ³
                ts = int(raw_ts * 1000)
            elif 1e12 <= raw_ts < 1e13:  # æ¯«ç§’çº§æ—¶é—´æˆ³
                ts = int(raw_ts)
            else:
                logger.warning(f"å¼‚å¸¸æ—¶é—´æˆ³æ ¼å¼: {raw_ts}")
                continue

            # æ•°æ®æœ‰æ•ˆæ€§éªŒè¯
            o, h, l, c, v = map(float, row[1:])
            if not (0 < o <= h and l <= c <= h and l > 0 and v >= 0):
                logger.debug(f"æ— æ•ˆæ•°æ®è¡Œ: {row}")
                continue

            valid.append((symbol, ts, o, h, l, c, v))
            min_ts = min(min_ts, ts)
            max_ts = max(max_ts, ts)

        if not valid:
            logger.warning(f"æ— æœ‰æ•ˆæ•°æ®å¯ä¿å­˜: {symbol} {timeframe}")
            return 0

        # åˆ†å—å†™å…¥æ•°æ®åº“
        try:
            conn = sqlite3.connect(**self.conn_params)
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA synchronous=NORMAL')

            for i in range(0, len(valid), chunk_size):
                chunk = valid[i:i+chunk_size]
                try:
                    # æ‰¹é‡æ’å…¥æ•°æ®
                    conn.executemany(
                        f'''INSERT OR REPLACE INTO {table}
                            (symbol, timestamp, open, high, low, close, volume)
                            VALUES (?,?,?,?,?,?,?)''',
                        chunk
                    )
                    
                    # æ›´æ–°å…ƒæ•°æ®
                    conn.execute('''
                        INSERT OR REPLACE INTO symbol_metadata 
                        (symbol, first_ts, last_ts, list_time)
                        VALUES (
                            ?,
                            COALESCE((SELECT MIN(first_ts) FROM symbol_metadata WHERE symbol=?), ?),
                            COALESCE((SELECT MAX(last_ts) FROM symbol_metadata WHERE symbol=?), ?),
                            (SELECT list_time FROM symbol_metadata WHERE symbol=?)
                        )
                    ''', (symbol, symbol, min_ts, symbol, max_ts, symbol))
                    
                    conn.commit()
                    saved += conn.total_changes
                    logger.debug(f"å·²å†™å…¥ {len(chunk)} æ¡æ•°æ®åˆ° {table}")

                except sqlite3.IntegrityError as e:
                    logger.error(f"æ•°æ®å†²çª: {str(e)}")
                    conn.rollback()
                except sqlite3.OperationalError as e:
                    if "locked" in str(e):
                        logger.warning("æ•°æ®åº“é”å®šï¼Œç­‰å¾…åé‡è¯•...")
                        time.sleep(0.5)
                        conn.rollback()
                        # é‡è¯•å½“å‰åˆ†å—
                        i -= chunk_size  
                    else:
                        raise

            # æ›´æ–°ç¼“å­˜
            with self.metadata_lock:
            # ç›´æ¥ä»æ•°æ®åº“è·å–æœ€æ–°å€¼ä¿è¯ä¸€è‡´æ€§
                current_first = self.get_oldest_timestamp(symbol, timeframe) or float('inf')
                current_last = self.get_last_timestamp(symbol, timeframe) or -float('inf')
                
                new_first = min(current_first, min_ts)
                new_last = max(current_last, max_ts)
                
                # å¼ºåˆ¶ç±»å‹è½¬æ¢
                self.symbol_metadata[symbol] = {
                    'first_ts': int(new_first),
                    'last_ts': int(new_last),
                    'list_time': self.symbol_metadata.get(symbol, {}).get('list_time')
                }
                logger.debug(f"å…ƒæ•°æ®æ›´æ–° {symbol}: {self.symbol_metadata[symbol]}")

            logger.info(f"æˆåŠŸä¿å­˜{symbol} {timeframe}æ•°æ® {saved}æ¡")
            return saved

        except Exception as e:
            logger.error(f"æ•°æ®åº“å†™å…¥å¤±è´¥: {str(e)}", exc_info=True)
            conn.rollback()
            return saved
        finally:
            if conn:
                conn.close()

    def _validate_ohlcv_row(self, row: list) -> bool:
        if len(row) != 6:
            return False
        ts, o, h, l, c, v = row
        return (
            0 < o <= h and 
            l <= c <= h and 
            l > 0 and 
            v >= 0 and 
            1_614_393_600_000 <= ts <= 4_102_444_800_000
        )

    def _get_symbol_metadata(self, symbol: str) -> dict:
        if symbol in self.symbol_metadata:
            return self.symbol_metadata[symbol]
        
        # å¢å¼ºåˆå§‹åŒ–é€»è¾‘
        default_ts = int(time.time() * 1000)
        with self.metadata_lock:
            with sqlite3.connect(**self.conn_params) as conn:
                row = conn.execute('''
                    SELECT first_ts, last_ts, list_time 
                    FROM symbol_metadata 
                    WHERE symbol = ?
                ''', (symbol,)).fetchone()
                
                if row:
                    # å¤„ç†æ•°æ®åº“NULLå€¼
                    first_ts = row[0] if row[0] is not None else default_ts
                    last_ts = row[1] if row[1] is not None else default_ts
                    meta = {
                        'first_ts': min(first_ts, last_ts),
                        'last_ts': max(first_ts, last_ts),
                        'list_time': row[2]
                    }
                    if row[0] is None or row[1] is None:
                        logger.warning(f"ä¿®å¤å…ƒæ•°æ®ç©ºå€¼ {symbol}")
                else:
                    list_time = self._fetch_list_time(symbol)
                    meta = {
                        'first_ts': default_ts,
                        'last_ts': default_ts,
                        'list_time': list_time
                    }
                    conn.execute('''
                        INSERT INTO symbol_metadata 
                        (symbol, first_ts, last_ts, list_time)
                        VALUES (?, ?, ?, ?)
                    ''', (symbol, default_ts, default_ts, list_time))
                    conn.commit()
                    logger.info(f"æ–°å»ºå…ƒæ•°æ®è®°å½• {symbol}")
                
                # å¼ºåˆ¶ç±»å‹æ ¡éªŒ
                meta['first_ts'] = int(meta['first_ts'])
                meta['last_ts'] = int(meta['last_ts'])
                self.symbol_metadata[symbol] = meta
                return meta
           
    def _fetch_list_time(self, symbol: str) -> int:
        """å¼ºåŒ–ä¸Šå¸‚æ—¶é—´è·å–é€»è¾‘"""
        try:
            exchange = self.store.exchange
            markets = exchange.load_markets(reload=True)
            
            if exchange.id == 'okx':
                inst_id = symbol.replace('/', '-')
                response = exchange.publicGetPublicInstruments({
                    'instType': 'SPOT', 
                    'instId': inst_id
                })
                list_time = int(response['data'][0]['listTime'])
            else:
                market = markets.get(symbol)
                list_time = market['info'].get('listing_date', market['timestamp'])
            
            # æ—¶é—´æˆ³æœ‰æ•ˆæ€§éªŒè¯
            current_ts = int(time.time() * 1000)
            if not (1000000000000 < list_time < current_ts):
                raise ValueError("Invalid listing time")
                
            return list_time
        except Exception as e:
            logger.error(f"è·å–ä¸Šå¸‚æ—¶é—´å¤±è´¥: {symbol} {str(e)}")
            # é»˜è®¤è¿”å›1å¹´å‰æ—¶é—´æˆ³
            return int((datetime.now(timezone.utc) - timedelta(days=365)).timestamp() * 1000)

    def fill_history(self, symbol: str, timeframe: str):
        """é‡æ„åçš„æ™ºèƒ½è¡¥å…¨æ–¹æ³•"""
        metadata = self._get_symbol_metadata(symbol)
        list_time = metadata['list_time']
        now_ts = int(time.time() * 1000)
        tf_ms = self._timeframe_to_ms(timeframe)
        
        # åŠ¨æ€è®¾ç½®æ—¶é—´èŒƒå›´
        if timeframe == '1h':
            max_days = 365
        elif timeframe == '1m':
            max_days = 30
        else:
            return

        end_ts = self._align_ts(now_ts, tf_ms)
        start_ts = end_ts - (max_days * 86400_000)
        actual_start_ts = max(list_time, start_ts)
        
        # è¯»å–åŒæ­¥è¿›åº¦
        saved_progress = self._get_sync_progress(symbol, timeframe)
        last_in_db = self.get_last_timestamp(symbol, timeframe)
        end_ts = min(last_in_db, end_ts) if last_in_db else end_ts
        current_ts = saved_progress if saved_progress else end_ts
        
        logger.info(f"æ™ºèƒ½è¡¥å…¨èŒƒå›´: {self._ts_to_str(actual_start_ts)} -> {self._ts_to_str(end_ts)}")
        
        success = False
        retry_count = 0  # æ–°å¢é‡è¯•è®¡æ•°å™¨
        with self.hist_lock, tqdm(desc=f"ğŸ“š {symbol} {timeframe}", unit="é¡µ") as pbar:
            try:
                while current_ts > actual_start_ts and retry_count < 5:  # æœ€å¤§é‡è¯•5æ¬¡
                    batch_start = max(current_ts - 1000 * tf_ms, actual_start_ts)
                    
                    data = self._safe_fetch_ohlcv(
                        symbol, timeframe, 
                        since=batch_start,
                        limit=1000
                    )
                    
                    if not data:
                        retry_count += 1
                        logger.warning(f"ç©ºæ•°æ®å“åº”ï¼Œé‡è¯•è®¡æ•°: {retry_count}")
                        time.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                        continue
                    
                    retry_count = 0  # é‡ç½®è®¡æ•°å™¨
                    
                    valid_data = [row for row in data if actual_start_ts <= row[0] <= end_ts]
                    if not valid_data or valid_data[0][0] >= current_ts:
                        break
                    
                    self.save_ohlcv_batch(symbol, timeframe, valid_data)
                    pbar.update(len(valid_data))
                    current_ts = self._align_ts(valid_data[0][0] - tf_ms, tf_ms)
                    self._save_progress(symbol, timeframe, current_ts)
                    
                    time.sleep(max(0.3, self.store.exchange.rateLimit / 3000))
                
                oldest = self.get_oldest_timestamp(symbol, timeframe)
                latest = self.get_last_timestamp(symbol, timeframe)
                if not oldest or not latest:
                    success = False
                else:
                    tolerance = 7 * 86400_000
                    success = (
                        (oldest <= actual_start_ts + tolerance) and 
                        (latest >= end_ts - tolerance)
                    )
            except Exception as e:
                logger.error(f"è¡¥å…¨ä¸­æ–­: {symbol} {timeframe} {str(e)}")
                self._save_progress(symbol, timeframe, current_ts)
                success = False
        
        if success:
            logger.info(f"è¡¥å…¨å®Œæˆ: {symbol} {timeframe}")
            self._mark_as_repaired(symbol, timeframe)
        else:
            logger.warning(f"æ•°æ®ä¸å®Œæ•´: {symbol} {timeframe} æœ€æ–°èŒƒå›´:{self._ts_to_str(oldest)}-{self._ts_to_str(latest)}")
    
    def _mark_as_repaired(self, symbol: str, timeframe: str):
        """æ ‡è®°æ•°æ®å·²ä¿®å¤"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO sync_progress 
                (symbol, timeframe, last_ts) 
                VALUES (?, ?, ?)
            ''', (symbol, timeframe, int(time.time()*1000)))
            conn.commit()

    def _save_progress(self, symbol, tf, current_ts):
        """ä¿å­˜è¡¥å…¨è¿›åº¦"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO sync_progress 
                (symbol, timeframe, last_ts) 
                VALUES (?, ?, ?)
            ''', (symbol, tf, current_ts))
            conn.commit()

    def _get_sync_progress(self, symbol, tf):
        """è·å–è¡¥å…¨è¿›åº¦"""
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute('''
                SELECT last_ts FROM sync_progress
                WHERE symbol=? AND timeframe=?
            ''', (symbol, tf)).fetchone()
            return row[0] if row else None

    @retry(stop=stop_after_attempt(3),
       wait=wait_fixed(2),
       retry=retry_if_exception_type((ccxt.NetworkError, ccxt.ExchangeError, KeyError)))
    def _safe_fetch_ohlcv(self, symbol: str, timeframe: str, since: int, limit: int):
        """æ•°æ®è·å–æ–¹æ³•"""
        retries = 0
        max_retries = 3
        tf_ms = self._timeframe_to_ms(timeframe)
        
        while retries < max_retries:
            try:
                # è‡ªåŠ¨è®¡ç®—endæ—¶é—´æˆ³
                end = since + (limit * tf_ms)
                
                # ä¸¥æ ¼å¯¹é½æ—¶é—´æˆ³
                aligned_since = self._align_ts(since, tf_ms)
                aligned_end = self._align_ts(end, tf_ms)
                
                data = self.store.exchange.fetch_ohlcv(
                    symbol,
                    timeframe=timeframe,
                    since=aligned_since,
                    limit=limit,
                    params={'instType': 'SPOT'}
                )
                
                # å¢å¼ºæ—¶é—´åºåˆ—éªŒè¯
                if data:
                    prev_ts = data[0][0]
                    for row in data[1:]:
                        current_ts = row[0]
                        if current_ts <= prev_ts:
                            raise ValueError(f"æ—¶é—´æˆ³éé€’å¢ {prev_ts} -> {current_ts}")
                        if current_ts > aligned_end:
                            raise ValueError(f"æ•°æ®è¶…å‡ºèŒƒå›´ {current_ts} > {aligned_end}")
                        prev_ts = current_ts

                return data
            
            except ccxt.NetworkError as e:
                logger.warning(f"ç½‘ç»œé”™è¯¯({retries+1}/{max_retries}): {str(e)}")
                time.sleep(2 ** retries)
                retries += 1
            
            except ccxt.ExchangeError as e:
                logger.warning(f"äº¤æ˜“æ‰€é”™è¯¯({retries+1}/{max_retries}): {str(e)}")
                time.sleep(2 ** retries)
                retries += 1
            
            except ccxt.RateLimitExceeded as e:
                logger.warning(f"APIé¢‘ç‡é™åˆ¶è§¦å‘ï¼Œç­‰å¾…åé‡è¯•: {str(e)}")
                time.sleep(60)
                return []
            
            except Exception as e:
                logger.error(f"æ•°æ®è·å–å¤±è´¥: {str(e)}")
                raise

        return []        
    
    def _start_writer_thread(self):
        """å¯åŠ¨å¼‚æ­¥å†™å…¥çº¿ç¨‹"""
        def writer():
            while True:
                try:
                    task = self.write_queue.get(timeout=5)
                    if task is None:
                        break
                    self.save_ohlcv_batch(**task)
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                    
        threading.Thread(target=writer, daemon=True, name="DBWriter").start()

    @staticmethod
    def _align_ts(ts: int, timeframe_ms: int) -> int:
        return ts if (ts % timeframe_ms == 0) else ((ts // timeframe_ms) + 1) * timeframe_ms

    @staticmethod
    def _timeframe_to_ms(timeframe: str) -> int:
        return {
            '1m': 60_000,
            '1h': 3_600_000,
            '1d': 86_400_000
        }[timeframe]

    def get_ohlcv_count(self, symbol: str, timeframe: str) -> int:
        """è·å–æ•°æ®é‡"""
        table = f'ohlcv_{timeframe}'
        with sqlite3.connect(**self.conn_params) as conn:
            return conn.execute(f'SELECT COUNT(*) FROM {table} WHERE symbol = ?', (symbol,)).fetchone()[0]

    def get_last_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        """è·å–æœ€æ–°æ—¶é—´æˆ³"""
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute(
                f'SELECT MAX(timestamp) FROM ohlcv_{timeframe} WHERE symbol = ?',
                (symbol,)
            ).fetchone()
            return row[0] if row else None

    def check_and_fill_gaps(self, symbol: str, timeframe: str, start_ts: int = None, end_ts: int = None):
        """ç¼ºå£å¤„ç†"""
        if not self._should_process(symbol, timeframe, 'gap'):
            return

        try:
            with self.gap_lock:  # ä½¿ç”¨withè¯­å¥ç¡®ä¿é”çš„é‡Šæ”¾
                logger.info(f"ğŸ—ï¸ å¯åŠ¨ç¼ºå£æ‰«æ: {symbol} {timeframe}")
                
                # å¦‚æœæœªæŒ‡å®šèŒƒå›´åˆ™è‡ªåŠ¨æ£€æµ‹
                if start_ts is None or end_ts is None:
                    gaps = self._precision_detect_gaps(symbol, timeframe)
                else:
                    # ç›´æ¥åˆ›å»ºæŒ‡å®šèŒƒå›´çš„ç¼ºå£
                    gaps = [(start_ts, end_ts)]
                
                # æœ‰æ•ˆæ€§éªŒè¯
                valid_gaps = []
                for start, end in gaps:
                    if start >= end:
                        continue
                    if end > int(time.time()*1000):
                        end = int(time.time()*1000)
                    valid_gaps.append((start, end))
                
                if not valid_gaps:  # æ–°å¢åˆ¤æ–­
                    logger.info("æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ•°æ®ç¼ºå£")
                    return
                
                with tqdm(
                    total=len(valid_gaps),
                    desc=f"ğŸ”§ {symbol} {timeframe} ç¼ºå£ä¿®å¤",
                    bar_format="{desc}: {percentage:.0f}%|{bar}| {n_fmt}/{total_fmt}"
                ) as pbar:
                    success_count = 0
                    for start, end in valid_gaps:
                        if self._fill_single_gap(symbol, timeframe, start, end, pbar):
                            success_count += 1
                        pbar.update(1)
                        if self._stop_event.is_set():  # æ–°å¢é€€å‡ºæ£€æŸ¥
                            break
                    
                    status_msg = (
                        f"ç¼ºå£å¤„ç†å®Œæˆ | æœ‰æ•ˆç¼ºå£: {len(valid_gaps)}ä¸ª | "
                        f"æˆåŠŸ: {success_count}ä¸ª | å¤±è´¥: {len(valid_gaps)-success_count}ä¸ª"
                    )
                    logger.info(status_msg)
        except Exception as e:
            logger.error(f"ç¼ºå£å¤„ç†å¼‚å¸¸: {str(e)}", exc_info=True)
        finally:
            self._clean_processed_gaps(symbol, timeframe)

    def _record_failed_gaps(self, symbol: str, timeframe: str, start: int, end: int):
        """è®°å½•å¤±è´¥ç¼ºå£"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('''
                UPDATE data_gaps SET 
                    retries = retries + 1,
                    next_retry_ts = ?
                WHERE symbol=? AND timeframe=? AND start_ts=?
            ''', (int(time.time()*1000) + 3600000, symbol, timeframe, start))
            conn.commit()

    def _fill_single_gap(self, symbol, tf, start, end, pbar):
        """ä¼˜åŒ–ç‰ˆå•ç¼ºå£è¡¥å…¨"""
        tf_ms = self._timeframe_to_ms(tf)
        current = start
        success = False
        
        try:
            while current <= end:
                data = self._safe_fetch_ohlcv(symbol, tf, current, 1000)
                if not data:
                    break
                
                # ä½¿ç”¨æ–°çš„èŒƒå›´è¿‡æ»¤æ–¹æ³•
                valid = self._filter_data_by_range(data, start, end)
                if not valid:
                    break
                
                self.save_ohlcv_batch(symbol, tf, valid)
                pbar.update(len(valid))
                current = valid[-1][0] + tf_ms
                success = True
            
            return success
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {start}-{end}: {str(e)}")
            return False

    def _filter_data_by_range(self, data, start, end):
        """ç»Ÿä¸€æ•°æ®è¿‡æ»¤æ–¹æ³•"""
        return [d for d in data if start <= d[0] <= end]

    def _precision_detect_gaps(self, symbol, tf):
        """ç²¾ç¡®ç¼ºå£"""
        table = f'ohlcv_{tf}'
        step = self._timeframe_to_ms(tf)
        gaps = []
        current_ts = int(time.time() * 1000)
        
        with sqlite3.connect(**self.conn_params) as conn:
            # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥
            df = pd.read_sql(f'''
                SELECT timestamp 
                FROM {table}
                WHERE symbol = ? 
                AND timestamp <= ?
                ORDER BY timestamp
            ''', conn, params=(symbol, current_ts))
            
            if len(df) < 2:
                return []
            
            df['prev'] = df['timestamp'].shift(1)
            df['gap'] = df['timestamp'] - df['prev'] - step
            # æ”¾å®½ç¼ºå£æ£€æµ‹é˜ˆå€¼
            anomalies = df[(df['gap'] > step * 1.05) & (df['gap'] < step * 2000)]  # ä»1.1æ”¹ä¸º1.05
            
            for _, row in anomalies.iterrows():
                gap_start = int(row['prev'] + step)
                gap_end = int(row['timestamp'] - step)
                # è¿‡æ»¤æ— æ•ˆå°ç¼ºå£
                if gap_end - gap_start < step * 2:  # è‡³å°‘ç¼º2æ ¹Kçº¿
                    continue
                gaps.append((
                    gap_start,
                    min(gap_end, current_ts)
                ))
        
        last_ts = df['timestamp'].iloc[-1]
        if last_ts < current_ts - step:
            gaps.append((
                last_ts + step,
                current_ts
            ))
        return gaps

       
    def save_plot_data(self, symbol: str, timeframe: str, data: dict):
        try:
            # å¢å¼ºæ•°æ®éªŒè¯
            required_fields = ['time', 'price', 'ma', 'rsi', 'atr', 'signals']
            if not all(field in data for field in required_fields):
                raise ValueError("ç¼ºå¤±å¿…è¦å­—æ®µ")
                
            if len({len(data[f]) for f in required_fields}) != 1:
                raise ValueError("æ‰€æœ‰æ•°æ®å­—æ®µé•¿åº¦å¿…é¡»ä¸€è‡´")

            df = pd.DataFrame({
                'time': pd.to_datetime(data['time'], unit='ms', utc=True),
                'symbol': symbol,
                'timeframe': timeframe,
                'price': pd.to_numeric(data['price'], errors='coerce'),
                'ma': pd.to_numeric(data['ma'], errors='coerce'),
                'rsi': pd.to_numeric(data['rsi'], errors='coerce'),
                'atr': pd.to_numeric(data['atr'], errors='coerce'),
                'signals': data['signals']
            }).dropna(subset=['price', 'ma', 'rsi'])

            # å¼ºåˆ¶ç±»å‹è½¬æ¢
            df['time'] = df['time'].astype('datetime64[ms]')
            numeric_cols = ['price', 'ma', 'rsi', 'atr']
            df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

            # ä½¿ç”¨äº‹åŠ¡å†™å…¥
            try:
                self.write_queue.put({
                    'type': 'plot',
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'data': df
                }, block=True, timeout=10)
            except queue.Full:
                logger.warning(f"ç»˜å›¾æ•°æ®é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒ{symbol} {timeframe}æ•°æ®")
                
        except Exception as e:
            logger.error(f"å‡†å¤‡ç»˜å›¾æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)

    def get_oldest_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        """è·å–æœ€æ—©æ—¶é—´æˆ³"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            row = conn.execute(f'''
                SELECT MIN(timestamp) FROM {table}
                WHERE symbol = ?
            ''', (symbol,)).fetchone()
            return row[0] if row[0] else None
    @retry(stop=stop_after_attempt(3), wait=wait_fixed(60))
    def sync_symbol(self, symbol: str):
        try:
            # å…ˆæ‰§è¡Œå†å²æ•°æ®è¡¥å…¨
            if self.config.get('fill_history', False):
                logger.info(f"å¼ºåˆ¶å†å²æ•°æ®è¡¥å…¨: {symbol}")
                for tf in ['1h', '1m']:  # å…ˆå°æ—¶çº¿ååˆ†é’Ÿçº¿
                    self.fill_history(symbol, tf)
                return True
            # åŸæœ‰å®æ—¶åŒæ­¥
            if not self.fetch_ohlcv(symbol):
                return False
            return True
        except Exception as e:
            logger.error(f"åŒæ­¥å¤±è´¥: {symbol} - {str(e)}")
            return False
    
    def _clear_existing_data(self, symbol: str, timeframe: str):
        """æ¸…é™¤ç°æœ‰æ•°æ®ä»¥å¼ºåˆ¶é‡æ–°åŒæ­¥"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            conn.execute(f'DELETE FROM {table} WHERE symbol = ?', (symbol,))
            logger.warning(f"å·²æ¸…é™¤{symbol} {timeframe}çš„ç°æœ‰æ•°æ®")

    def set_progress_queue(self, queue):
        self.progress_queue = queue

    def _update_progress(self, n: int = 1):
        if self.progress:
            self.progress.update(n)
            if self.progress_queue:
                try:
                    self.progress_queue.put_nowait((
                        self.current_symbol,
                        self.current_tf,
                        self.progress.n,
                        self.progress.total
                    ))
                except queue.Full:
                    pass
    
    def ensure_data_range(self, symbol: str, timeframe: str) -> bool:
        # ç²¾ç¡®è®¡ç®—æ¯«ç§’æ—¶é—´æˆ³
        now = int(time.time() * 1000)
        if timeframe == '1h':
            required_start = now - (365 * 86400_000)  # 365å¤©
        elif timeframe == '1m':
            required_start = now - (30 * 86400_000)    # 30å¤©
        else:
            return True

        # è·å–å®é™…æ•°æ®è¾¹ç•Œï¼ˆå¢å¼ºç©ºå€¼å¤„ç†ï¼‰
        oldest = self.get_oldest_timestamp(symbol, timeframe)
        latest = self.get_last_timestamp(symbol, timeframe)
        if not oldest or not latest:
            logger.error(f"è·å–æ—¶é—´æˆ³å¤±è´¥ï¼Œå¼ºåˆ¶å…¨é‡è¡¥å…¨")
            return self._fill_range(symbol, timeframe, required_start, now)
        
        # åŠ¨æ€è°ƒæ•´è¦æ±‚ï¼ˆå…è®¸7å¤©ç¼ºå£ï¼‰
        tolerance = 7 * 86400_000
        success = (oldest <= required_start + tolerance) and (latest >= now - tolerance)
        
        if not success:
            logger.warning(f"æ•°æ®èŒƒå›´å¼‚å¸¸ {symbol} {timeframe} | ç°æœ‰èŒƒå›´: {self._ts_to_str(oldest)}-{self._ts_to_str(latest)} | éœ€æ±‚èŒƒå›´: {self._ts_to_str(required_start)}-{self._ts_to_str(now)}")
            return self._fill_range(symbol, timeframe, required_start, now)
        return True
    
    @staticmethod
    def _ts_to_str(ts: int) -> str:
        return datetime.fromtimestamp(ts/1000).strftime('%Y-%m-%d %H:%M')

    def _fill_range(self, symbol: str, timeframe: str, start: int, end: int) -> bool:
        """ç²¾ç¡®å¡«å……æ—¶é—´èŒƒå›´"""
        tf_ms = self._timeframe_to_ms(timeframe)
        current = end
        total = 0
        max_attempts = 1000
        retry_count = 0
        logger.info(f"å¼ºåˆ¶è¡¥å…¨èŒƒå›´: {self._ts_to_str(start)}->{self._ts_to_str(end)} å…±{(end-start)/tf_ms}æ ¹Kçº¿")
        
        with tqdm(total=(end - start)//tf_ms + 1,  # ä¿®æ­£æ€»æ•°è®¡ç®—
                 desc=f"ç´§æ€¥è¡¥å…¨{symbol} {timeframe}") as pbar:
            for _ in range(max_attempts):
                if current < start:  # ä¿®æ”¹ç»ˆæ­¢æ¡ä»¶
                    break
                
                try:
                    data = self._safe_fetch_ohlcv(
                        symbol, timeframe, 
                        current - 1000*tf_ms, 
                        1000
                    )
                    if not data:
                        if retry_count > 3:
                            break
                        retry_count += 1
                        continue
                    
                    # æ‰©å±•æœ‰æ•ˆèŒƒå›´åˆ¤æ–­
                    valid = [d for d in data if (start - tf_ms) <= d[0] <= end]
                    if not valid:
                        break
                    
                    # æ›´æ–°å½“å‰æŒ‡é’ˆæ—¶åº”ä½¿ç”¨æœ€å°æ—¶é—´æˆ³
                    current = min(d[0] for d in valid) - tf_ms
                    self.save_ohlcv_batch(symbol, timeframe, valid)
                    saved = len(valid)
                    total += saved
                    pbar.update(saved)
                    retry_count = 0
                    
                    # åŠ¨æ€è°ƒæ•´è¯·æ±‚é—´éš”
                    delay = max(
                        self.store.exchange.rateLimit / 1000, 
                        0.5 if saved < 500 else 0.1
                    )
                    time.sleep(delay)
                    
                except Exception as e:
                    logger.error(f"è¡¥å…¨å¼‚å¸¸: {str(e)}")
                    break

        logger.info(f"è¡¥å…¨å®Œæˆï¼Œå®é™…éœ€æ±‚/å†™å…¥: {(end-start)//tf_ms+1}/{total}")
        return total > 0

    def _validate_timestamp_continuity(self, symbol: str, timeframe: str):
        """æ—¶é—´è¿ç»­æ€§æ ¡éªŒ"""
        table = f'ohlcv_{"1m" if timeframe == "1m" else "1h"}'
        expected_step = self._timeframe_to_ms(timeframe)
        
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            df = pd.read_sql(f'''
                SELECT timestamp,
                       (timestamp - LAG(timestamp) OVER (ORDER BY timestamp)) AS diff
                FROM {table}
                WHERE symbol = '{symbol}'
                ORDER BY timestamp
            ''', conn)
            
            anomalies = df[df['diff'] > (expected_step + 1000)]
            if not anomalies.empty:
                logger.warning(f"å‘ç°{len(anomalies)}å¤„æ—¶é—´å¼‚å¸¸ {symbol} {timeframe}")

    def set_progress_queue(self, queue):
        """è®¾ç½®å¯è§†åŒ–è¿›åº¦é˜Ÿåˆ—"""
        self.progress_queue = queue

    def auto_repair_gaps(self):
        """åå°è‡ªåŠ¨ä¿®å¤ç¼ºå£"""
        while True:
            try:
                for symbol in self.config['spot_symbols']:
                    for tf in ['1m', '1h']:
                        if self._precision_detect_gaps(symbol, tf) > 0:
                            self._fill_gaps(symbol, tf)
                time.sleep(3600)  # æ¯å°æ—¶è¿è¡Œä¸€æ¬¡
            except Exception as e:
                logger.error(f"è‡ªåŠ¨ä¿®å¤å¼‚å¸¸: {str(e)}")

    def _get_symbol_list_time(self, symbol: str) -> int:
        """å¼ºåŒ–ä¸Šå¸‚æ—¶é—´è·å–é€»è¾‘"""
        if symbol in self.symbol_metadata:
            return self.symbol_metadata[symbol]['list_time']

        try:
            markets = self.store.exchange.load_markets(reload=True)
            market = markets.get(symbol)
            if not market:
                logger.error(f"æ‰¾ä¸åˆ°äº¤æ˜“å¯¹: {symbol}")
                return self._default_list_time()

            # å¤šäº¤æ˜“æ‰€å…¼å®¹é€»è¾‘
            exchange_name = self.config['exchange']['name'].lower()
            info = market.get('info', {})
            
            # OKXç‰¹æ®Šå¤„ç†
            if exchange_name == 'okx':
                list_time = int(info.get('listTime', 0))
                if list_time == 0:
                    # ä»å¸ç§ä¿¡æ¯ä¸­æå–
                    inst_id = market['id']
                    response = self.store.exchange.publicGetPublicInstruments(params={
                        'instType': 'SPOT',
                        'instId': inst_id
                    })
                    list_time = int(response['data'][0]['listTime'])
            else:
                # å…¶ä»–äº¤æ˜“æ‰€å¤„ç†
                list_time = market.get('timestamp', None) or info.get('listing_date', 0)
            
            # æœ€ç»ˆæ ¡éªŒ
            current_ts = int(time.time() * 1000)
            if not (1000000000000 < list_time < current_ts):
                logger.warning(f"å¼‚å¸¸ä¸Šå¸‚æ—¶é—´ {symbol}: {list_time}, ä½¿ç”¨é»˜è®¤å€¼")
                list_time = self._default_list_time()
            
            self.symbol_metadata[symbol] = {
                'list_time': list_time,
                'first_ts': None,
                'last_ts': None
            }
            logger.info(f"ç¡®å®šä¸Šå¸‚æ—¶é—´ {symbol}: {datetime.fromtimestamp(list_time/1000)}")
            return list_time
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šå¸‚æ—¶é—´å¤±è´¥ {symbol}: {str(e)}")
            return self._default_list_time()
        
    def _align_timestamp(self, ts: int, timeframe: str) -> int:
        """ç­–ç•¥çº§æ—¶é—´å¯¹é½ï¼ˆæ”¯æŒå¤šæ—¶é—´å¸§ï¼‰"""
        if timeframe == '1h':
            return ts - (ts % 3_600_000)  # æ•´å°æ—¶å¯¹é½
        elif timeframe == '1m':
            return ts - (ts % 60_000)     # æ•´åˆ†é’Ÿå¯¹é½
        else:
            return ts
    
    def _db_writer_loop(self):
        """ä¸“ç”¨å†™çº¿ç¨‹å¾ªç¯"""
        while True:
            task = None
            try:
                task = self.write_queue.get(timeout=5)
                with self.db_lock:
                    conn = sqlite3.connect(self.db_path, timeout=30)
                    try:
                        conn.executemany(task['query'], task['data'])
                        conn.commit()
                        logger.debug(f"æ‰¹é‡å†™å…¥å®Œæˆ {len(task['data'])}æ¡")
                    finally:
                        conn.close()
            except queue.Empty:
                continue
            except sqlite3.OperationalError as e:
                logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œç­‰å¾…åé‡è¯•: {str(e)}")
                time.sleep(5)
            except Exception as e:
                logger.error(f"æ•°æ®åº“å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
                time.sleep(5)

            finally:
                if task is not None:
                    self.write_queue.task_done()
    
    def _safe_release_lock(self, lock: threading.Lock):
        """å®‰å…¨é‡Šæ”¾é”"""
        try:
            if lock.locked():
                lock.release()
        except RuntimeError as e:
            logger.warning(f"é”é‡Šæ”¾å¼‚å¸¸: {str(e)}")

    def _start_writer_thread(self):
        """ç»Ÿä¸€ç‰ˆå†™å…¥çº¿ç¨‹"""
        def writer():
            while True:
                try:
                    task = self.write_queue.get(timeout=5)
                    if task is None:  # æ¥æ”¶åˆ°ç»ˆæ­¢ä¿¡å·
                        break
                        
                    # åŠ¨æ€å¤„ç†ä»»åŠ¡ç±»å‹
                    if task['type'] == 'ohlcv':
                        self._save_ohlcv_task(task)
                    elif task['type'] == 'plot':
                        self._save_plot_task(task)
                    elif task['type'] == 'sync':
                        self._handle_sync_task(task)
                        
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"å†™å…¥çº¿ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)

        threading.Thread(target=writer, daemon=True, name="DBWriter").start()

    def _save_ohlcv_task(self, task):
        """å¤„ç†OHLCVæ•°æ®å†™å…¥"""
        with sqlite3.connect(**self.conn_params) as conn:
            conn.executemany(
                task['query'],
                task['data']
            )
            conn.commit()

    def _save_plot_task(self, task):
        """ä¿å­˜ç»˜å›¾æ•°æ®"""
        df = task['data']
        try:
            with sqlite3.connect(**self.conn_params) as conn:
                df.to_sql('plot_data', conn, if_exists='append', index=False)
            logger.debug(f"ä¿å­˜ç»˜å›¾æ•°æ®æˆåŠŸ: {task['symbol']} {task['timeframe']} {len(df)}æ¡")
        except sqlite3.IntegrityError:
            logger.warning(f"å¿½ç•¥é‡å¤ç»˜å›¾æ•°æ®: {task['symbol']} {task['timeframe']}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç»˜å›¾æ•°æ®å¤±è´¥: {str(e)}")

    def get_ohlcv_count(self, symbol: str, timeframe: str) -> int:
        """è·å–æŒ‡å®šå“ç§çš„æ•°æ®é‡"""
        table = 'ohlcv_1m' if timeframe == '1m' else 'ohlcv_1h'
        with sqlite3.connect(**self.conn_params) as conn:
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA busy_timeout=5000')
            return conn.execute(f'''
                SELECT COUNT(*) FROM {table}
                WHERE symbol = ?
            ''', (symbol,)).fetchone()[0]
 
    def _should_process(self, symbol: str, tf: str, process_type: str) -> bool:
        config = ConfigManager().config
    
        # ä¸¥æ ¼æ£€æŸ¥å“ç§ç™½åå•
        if symbol not in config.get('spot_symbols', []):
            return False
        
        # ä½¿ç”¨å®‰å…¨è®¿é—®æ–¹å¼è·å–åµŒå¥—é…ç½®
        if process_type == 'gap':
            if not config.get('gap_fill', {}).get('enabled', False):
                return False
                
        elif process_type == 'historical':
            # å¢åŠ è¯¦ç»†æ—¥å¿—è¾“å‡º
            enabled = config.get('historical_fill', {}).get('enabled', False)
            logger.debug(f"å†å²è¡¥å…¨æ£€æŸ¥ {symbol} {tf}: é…ç½®çŠ¶æ€={enabled}")
            if not enabled:
                return False
            
        return True

    def print_lock_status(self):
        """è°ƒè¯•ç”¨é”çŠ¶æ€æ‰“å°"""
        status = {
            'hist_lock': self.hist_lock.locked(),
            'gap_lock': self.gap_lock.locked(),
            'write_queue_size': self.write_queue.qsize()
        }
        logger.debug(f"é”çŠ¶æ€: {status}")
    
    def _fill_gaps(self, symbol: str, timeframe: str, pbar: tqdm) -> int:
        filled = 0
        try:
            table = f'ohlcv_{timeframe}'
            expected_step = self._timeframe_to_ms(timeframe)
            
            with sqlite3.connect(**self.conn_params) as conn:
                # è·å–å¾…å¤„ç†ç¼ºå£
                gaps = conn.execute('''
                    SELECT start_ts, end_ts FROM data_gaps
                    WHERE symbol = ? AND timeframe = ?
                    ORDER BY start_ts
                ''', (symbol, timeframe)).fetchall()
                
                for start_ts, end_ts in gaps:
                    current = start_ts
                    while current < end_ts:
                        data = self._safe_fetch_ohlcv(
                            symbol, 
                            timeframe, 
                            current, 
                            1000
                        )
                        
                        if not data:
                            break
                            
                        # ä¸¥æ ¼è¿‡æ»¤æœ‰æ•ˆæ•°æ®èŒƒå›´
                        valid_data = [
                            row for row in data 
                            if start_ts <= row[0] <= end_ts
                        ]
                        
                        if not valid_data:
                            break
                        
                        # æ‰¹é‡ä¿å­˜æ•°æ®
                        self.save_ohlcv_batch(symbol, timeframe, valid_data)
                        filled += len(valid_data)
                        pbar.update(len(valid_data))
                        
                        # æ›´æ–°è¿›åº¦æŒ‡é’ˆ
                        current = valid_data[-1][0] + expected_step
                    
                    # åˆ é™¤å·²å¤„ç†ç¼ºå£
                    conn.execute('''
                        DELETE FROM data_gaps 
                        WHERE symbol=? AND timeframe=? AND start_ts=?
                    ''', (symbol, timeframe, start_ts))
                    conn.commit()
                    
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {symbol} {timeframe}: {str(e)}")
            return filled
        return filled
    
    def _default_list_time(self) -> int:
        return int((datetime.now(timezone.utc) - timedelta(days=365)).timestamp() * 1000)

    def _close_db_connections(self):
        if hasattr(self, 'conn') and self.conn:
            try:
                if self.conn.in_transaction:
                    self.conn.commit()  # æˆ–rollbackæ ¹æ®éœ€æ±‚
                self.conn.close()
                logger.debug("æ•°æ®åº“è¿æ¥å·²å®‰å…¨å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­è¿æ¥å¤±è´¥: {str(e)}")
            finally:
                self.conn = None

    def get_last_timestamp(self, symbol: str, timeframe: str) -> Optional[int]:
        table = f'ohlcv_{timeframe}'
        with sqlite3.connect(**self.conn_params) as conn:
            row = conn.execute(
                f'SELECT MAX(timestamp) FROM {table} WHERE symbol = ?',
                (symbol,)
            ).fetchone()
            return row[0] if row else None

    def _get_last_timestamp(self, symbol: str) -> int:
        with sqlite3.connect(**self.conn_params) as conn:
            cur = conn.execute('''
                SELECT MAX(timestamp) FROM ohlcv_1m WHERE symbol = ?
            ''', (symbol,))
            result = cur.fetchone()[0]
            return result or int((datetime.now() - timedelta(days=30)).timestamp() * 1000)

    def _safe_fetch_with_progress(self, symbol, tf, since, limit, pbar):
        """å¸¦è¿›åº¦è·Ÿè¸ªçš„æ•°æ®è·å–"""
        try:
            data = self._safe_fetch_ohlcv(symbol, tf, since, limit)
            if not data:
                return None
                
            valid = [row for row in data if row[0] > since]
            if valid:
                self.save_ohlcv_batch(symbol, tf, valid)
                pbar.update(len(valid))
            return valid
        except Exception as e:
            logger.error(f"è·å–å¤±è´¥: {symbol} {tf} {str(e)}")
            return None

    def _fill_single_gap(self, symbol, tf, start, end, pbar):
        """å•ç¼ºå£è¡¥å…¨"""
        tf_ms = self._timeframe_to_ms(tf)
        current = start
        success = False
        
        try:
            # è®¡ç®—éœ€è¦è·å–çš„Kçº¿æ•°é‡
            limit = ((end - start) // tf_ms) + 1  # åŠ¨æ€è®¡ç®—limit
            
            while current <= end:
                # ç²¾ç¡®å¯¹é½æ—¶é—´æˆ³
                aligned_current = self._align_ts(current, tf_ms)
                
                data = self._safe_fetch_ohlcv(
                    symbol, 
                    tf,
                    since=aligned_current,
                    limit=min(limit, 1000)  # æ§åˆ¶å•æ¬¡è¯·æ±‚é‡
                )
                
                if not data:
                    break
                
                # ä¸¥æ ¼è¿‡æ»¤åœ¨ç¼ºå£èŒƒå›´å†…çš„æ•°æ®
                valid = [row for row in data if start <= row[0] <= end]
                if not valid:
                    break
                    
                # ä¿å­˜æ•°æ®å¹¶æ›´æ–°è¿›åº¦
                saved = self.save_ohlcv_batch(symbol, tf, valid)
                if saved > 0:
                    pbar.update(saved)
                    current = valid[-1][0] + tf_ms
                    success = True
                else:
                    break
                
                # æ›´æ–°å‰©ä½™éœ€è¦è·å–çš„æ•°é‡
                limit -= len(valid)
                
        except Exception as e:
            logger.error(f"è¡¥å…¨ç¼ºå£å¤±è´¥ {start}-{end}: {str(e)}")
            return False
        
        # äºŒæ¬¡éªŒè¯ç¼ºå£æ˜¯å¦å¡«è¡¥
        with sqlite3.connect(**self.conn_params) as conn:
            gap_count = conn.execute('''
                SELECT COUNT(*) FROM data_gaps 
                WHERE symbol=? AND timeframe=? 
                AND start_ts=? AND end_ts=?
            ''', (symbol, tf, start, end)).fetchone()[0]
            
        return gap_count == 0 and success
    
    def _clean_processed_gaps(self, symbol: str, timeframe: str):
        """æ¸…ç†å·²å¤„ç†æˆ–è¿‡æœŸçš„ç¼ºå£è®°å½•"""
        try:
            with sqlite3.connect(**self.conn_params) as conn:
                # åˆ é™¤è¶…è¿‡3æ¬¡é‡è¯•çš„ç¼ºå£è®°å½•
                conn.execute('''
                    DELETE FROM data_gaps 
                    WHERE symbol = ? 
                    AND timeframe = ?
                    AND retries >= 3
                ''', (symbol, timeframe))
                
                # åˆ é™¤å·²ç»ä¸å­˜åœ¨æ—¶é—´èŒƒå›´å†…çš„ç¼ºå£ï¼ˆé˜²æ­¢æ®‹ç•™ï¼‰
                conn.execute('''
                    DELETE FROM data_gaps 
                    WHERE symbol = ? 
                    AND timeframe = ?
                    AND end_ts < (
                        SELECT MIN(timestamp) 
                        FROM ohlcv_''' + timeframe + '''
                        WHERE symbol = ?
                    )
                ''', (symbol, timeframe, symbol))
                
                conn.commit()
                logger.debug(f"æ¸…ç†å®Œæˆ {symbol} {timeframe} çš„è¿‡æœŸç¼ºå£è®°å½•")
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼ºå£è®°å½•å¤±è´¥: {str(e)}")

    def _convert_db_timestamp(self, ts: int) -> int:
        """å¤„ç†ä¸åŒæ¥æºçš„æ—¶é—´æˆ³æ ¼å¼"""
        if 1e12 <= ts < 1e13:  # æ¯«ç§’çº§æ—¶é—´æˆ³ (13ä½)
            return ts
        elif 1e9 <= ts < 1e10:  # ç§’çº§æ—¶é—´æˆ³ (10ä½)
            return ts * 1000
        else:
            logger.warning(f"å¼‚å¸¸æ—¶é—´æˆ³æ ¼å¼: {ts}")
            return int(time.time() * 1000)  # è¿”å›å½“å‰æ—¶é—´ä½œä¸ºé»˜è®¤å€¼
        
    def _validate_last_n_bars(self, symbol: str, timeframe: str, n: int = 3):
        """éªŒè¯æœ€ånæ ¹Kçº¿çš„è¿ç»­æ€§"""
        table = f'ohlcv_{timeframe}'
        tf_ms = self._timeframe_to_ms(timeframe)
        
        with sqlite3.connect(**self.conn_params) as conn:
            df = pd.read_sql_query(f'''
                SELECT timestamp 
                FROM {table} 
                WHERE symbol = ? 
                ORDER BY timestamp DESC 
                LIMIT {n}
            ''', conn, params=(symbol,))
            
        if len(df) < n:
            return
        
        # æ£€æŸ¥æ—¶é—´é—´éš”
        diffs = df['timestamp'].diff().abs().iloc[1:]
        anomalies = diffs[diffs != tf_ms]
        
        if not anomalies.empty:
            logger.warning(f"å‘ç°è¿‘æœŸæ•°æ®å¼‚å¸¸ {symbol} {timeframe}")
            # è§¦å‘ç´§æ€¥è¡¥å…¨
            start = df['timestamp'].min() - tf_ms * 10  # å¤šè¡¥10æ ¹ç¡®ä¿è¿ç»­
            end = df['timestamp'].max() + tf_ms
            self.check_and_fill_gaps(symbol, timeframe, start, end)